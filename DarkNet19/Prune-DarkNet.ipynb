{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torchvision import transforms, datasets\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "from PIL import Image\n",
    "\n",
    "import math\n",
    "import time\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DarkNet(nn.Module):\n",
    "    def __init__(self):\n",
    "\n",
    "        super(DarkNet, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.relu1 = nn.LeakyReLU(0.1)\n",
    "\n",
    "        self.pool1 = nn.MaxPool2d(2)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.relu2 = nn.LeakyReLU(0.1)\n",
    "\n",
    "        self.pool2 = nn.MaxPool2d(2)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        self.relu3 = nn.LeakyReLU(0.1)\n",
    "\n",
    "        self.conv4 = nn.Conv2d(in_channels=128, out_channels=64, kernel_size=1, stride=1, padding=1, bias=False)\n",
    "        self.bn4 = nn.BatchNorm2d(64)\n",
    "        self.relu4 = nn.LeakyReLU(0.1)\n",
    "\n",
    "        self.conv5 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn5 = nn.BatchNorm2d(128)\n",
    "        self.relu5 = nn.LeakyReLU(0.1)\n",
    "\n",
    "        self.pool5 = nn.MaxPool2d(2)\n",
    "\n",
    "        self.conv6 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn6 = nn.BatchNorm2d(256)\n",
    "        self.relu6 = nn.LeakyReLU(0.1)\n",
    "\n",
    "        self.conv7 = nn.Conv2d(in_channels=256, out_channels=128, kernel_size=1, stride=1, padding=1, bias=False)\n",
    "        self.bn7 = nn.BatchNorm2d(128)\n",
    "        self.relu7 = nn.LeakyReLU(0.1)\n",
    "\n",
    "        self.conv8 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn8 = nn.BatchNorm2d(256)\n",
    "        self.relu8 = nn.LeakyReLU(0.1)\n",
    "\n",
    "        self.pool8 = nn.MaxPool2d(2)\n",
    "\n",
    "        self.conv9 = nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn9 = nn.BatchNorm2d(512)\n",
    "        self.relu9 = nn.LeakyReLU(0.1)\n",
    "\n",
    "        self.conv10 = nn.Conv2d(in_channels=512, out_channels=256, kernel_size=1, stride=1, padding=1, bias=False)\n",
    "        self.bn10 = nn.BatchNorm2d(256)\n",
    "        self.relu10 = nn.LeakyReLU(0.1)\n",
    "\n",
    "        self.conv11 = nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn11 = nn.BatchNorm2d(512)\n",
    "        self.relu11 = nn.LeakyReLU(0.1)\n",
    "\n",
    "        self.conv12 = nn.Conv2d(in_channels=512, out_channels=256, kernel_size=1, stride=1, padding=1, bias=False)\n",
    "        self.bn12 = nn.BatchNorm2d(256)\n",
    "        self.relu12 = nn.LeakyReLU(0.1)\n",
    "\n",
    "        self.conv13 = nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn13 = nn.BatchNorm2d(512)\n",
    "        self.relu13 = nn.LeakyReLU(0.1)\n",
    "\n",
    "        self.pool13 = nn.MaxPool2d(2)\n",
    "\n",
    "        self.conv14 = nn.Conv2d(in_channels=512, out_channels=1024, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn14 = nn.BatchNorm2d(1024)\n",
    "        self.relu14 = nn.LeakyReLU(0.1)\n",
    "\n",
    "        self.conv15 = nn.Conv2d(in_channels=1024, out_channels=512, kernel_size=1, stride=1, padding=1, bias=False)\n",
    "        self.bn15 = nn.BatchNorm2d(512)\n",
    "        self.relu15 = nn.LeakyReLU(0.1)\n",
    "\n",
    "        self.conv16 = nn.Conv2d(in_channels=512, out_channels=1024, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn16 = nn.BatchNorm2d(1024)\n",
    "        self.relu16 = nn.LeakyReLU(0.1)\n",
    "\n",
    "        self.conv17 = nn.Conv2d(in_channels=1024, out_channels=512, kernel_size=1, stride=1, padding=1, bias=False)\n",
    "        self.bn17 = nn.BatchNorm2d(512)\n",
    "        self.relu17 = nn.LeakyReLU(0.1)\n",
    "        \n",
    "        self.conv18 = nn.Conv2d(in_channels=512, out_channels=1024, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn18 = nn.BatchNorm2d(1024)\n",
    "        self.relu18 = nn.LeakyReLU(0.1)\n",
    "\n",
    "        self.conv19 = nn.Conv2d(in_channels=1024, out_channels=30, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "\n",
    "        self.pool19 = nn.AvgPool2d(7)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.pool2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x)\n",
    "        x = self.relu3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.bn4(x)\n",
    "        x = self.relu4(x)\n",
    "        x = self.conv5(x)\n",
    "        x = self.bn5(x)\n",
    "        x = self.relu5(x)\n",
    "        x = self.pool5(x)\n",
    "        x = self.conv6(x)\n",
    "        x = self.bn6(x)\n",
    "        x = self.relu6(x)\n",
    "        x = self.conv7(x)\n",
    "        x = self.bn7(x)\n",
    "        x = self.relu7(x)\n",
    "        x = self.conv8(x)\n",
    "        x = self.bn8(x)\n",
    "        x = self.relu8(x)\n",
    "        x = self.pool8(x)\n",
    "        x = self.conv9(x)\n",
    "        x = self.bn9(x)\n",
    "        x = self.relu9(x)\n",
    "        x = self.conv10(x)\n",
    "        x = self.bn10(x)\n",
    "        x = self.relu10(x)\n",
    "        x = self.conv11(x)\n",
    "        x = self.bn11(x)\n",
    "        x = self.relu11(x)\n",
    "        x = self.conv12(x)\n",
    "        x = self.bn12(x)\n",
    "        x = self.relu12(x)\n",
    "        x = self.conv13(x)\n",
    "        x = self.bn13(x)\n",
    "        x = self.relu13(x)\n",
    "        x = self.pool13(x)\n",
    "        x = self.conv14(x)\n",
    "        x = self.bn14(x)\n",
    "        x = self.relu14(x)\n",
    "        x = self.conv15(x)\n",
    "        x = self.bn15(x)\n",
    "        x = self.relu15(x)\n",
    "        x = self.conv16(x)\n",
    "        x = self.bn16(x)\n",
    "        x = self.relu16(x)\n",
    "        x = self.conv17(x)\n",
    "        x = self.bn17(x)\n",
    "        x = self.relu17(x)\n",
    "        x = self.conv18(x)\n",
    "        x = self.conv19(x)\n",
    "        x = self.pool19(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batchsize = 32\n",
    "train_data_transform = transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        #transforms.RandomRotation(10),\n",
    "        #transforms.ColorJitter(hue=0.1,saturation=0.75),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        #transforms.RandomVerticalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                             std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "tset_data_transform = transforms.Compose([\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                             std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "train_dataset = torchvision.datasets.ImageFolder(root='/media/lulugay/PC/CCCV-30/train_set',transform=train_data_transform)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batchsize, shuffle=True, num_workers=8)\n",
    " \n",
    "val_dataset = torchvision.datasets.ImageFolder(root='/media/lulugay/PC/CCCV-30/test_set', transform=tset_data_transform)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batchsize, shuffle=True, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DarkNet()\n",
    "pruned_model = DarkNet()\n",
    "model.cuda()\n",
    "pruned_model.cuda()\n",
    "loss_func = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(net,data_loader):\n",
    "    corret,total = 0,0\n",
    "    running_loss = 0.0\n",
    "    for inputs,labels in data_loader:\n",
    "        inputs = inputs.cuda()\n",
    "        labels = labels.cuda()\n",
    "        outputs = net(Variable(inputs))\n",
    "        _,predicted = torch.max(outputs.data,1)\n",
    "        total += labels.size(0)\n",
    "        corret += (predicted == labels).sum()\n",
    "        accuracy = 100 * float(corret) / float(total)\n",
    "        loss = loss_func(outputs, labels)\n",
    "        running_loss += loss.data[0]\n",
    "    running_loss = running_loss / (15000 / batchsize)\n",
    "    print('Test Accuracy: %.4f %%, Loss: %.4f' % (accuracy,running_loss))\n",
    "    return accuracy,float(running_loss)\n",
    "\n",
    "def poly(base_lr,power,total_epoch,now_epoch):\n",
    "    return base_lr*(1-math.pow(float(now_epoch)/float(total_epoch),power))\n",
    "\n",
    "def get_layer_fm_index(index):\n",
    "    layer_index = 0\n",
    "    fm_index = 0\n",
    "    while (index >= model_config[layer_index]):\n",
    "        index = index - model_config[layer_index]\n",
    "        layer_index = layer_index + 1\n",
    "    fm_index = index\n",
    "    return layer_index,fm_index\n",
    "\n",
    "def get_index(layer_index,fm_index):\n",
    "    index = 0\n",
    "    for i in range (layer_index):\n",
    "        index = index + model_config[i]\n",
    "    index = index + fm_index\n",
    "    return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:23: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 20.3067 %, Loss: 2.7864\n",
      "test epoch0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:13: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "  del sys.path[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 21.0467 %, Loss: 2.7205\n",
      "epoch [1/80] need time 212.8345\n",
      "train epoch1\n",
      "Train Accuracy: 33.6400 %, Loss: 2.2433\n",
      "test epoch1\n",
      "Test Accuracy: 35.1267 %, Loss: 2.1964\n",
      "epoch [2/80] need time 214.7331\n",
      "train epoch2\n",
      "Train Accuracy: 40.5756 %, Loss: 1.9810\n",
      "test epoch2\n",
      "Test Accuracy: 40.2400 %, Loss: 1.9778\n",
      "epoch [3/80] need time 214.7800\n",
      "train epoch3\n",
      "Train Accuracy: 45.5578 %, Loss: 1.8056\n",
      "test epoch3\n",
      "Test Accuracy: 43.7733 %, Loss: 1.8627\n",
      "epoch [4/80] need time 214.7582\n",
      "train epoch4\n",
      "Train Accuracy: 49.1067 %, Loss: 1.6736\n",
      "test epoch4\n",
      "Test Accuracy: 39.6667 %, Loss: 2.0659\n",
      "epoch [5/80] need time 215.2308\n",
      "train epoch5\n",
      "Train Accuracy: 51.5511 %, Loss: 1.5752\n",
      "test epoch5\n",
      "Test Accuracy: 49.9467 %, Loss: 1.6453\n",
      "epoch [6/80] need time 214.9244\n",
      "train epoch6\n",
      "Train Accuracy: 54.1667 %, Loss: 1.4851\n",
      "test epoch6\n",
      "Test Accuracy: 49.0933 %, Loss: 1.6912\n",
      "epoch [7/80] need time 215.2587\n",
      "train epoch7\n",
      "Train Accuracy: 55.9889 %, Loss: 1.4171\n",
      "test epoch7\n",
      "Test Accuracy: 51.0733 %, Loss: 1.6276\n",
      "epoch [8/80] need time 214.9517\n",
      "train epoch8\n",
      "Train Accuracy: 57.8844 %, Loss: 1.3607\n",
      "test epoch8\n",
      "Test Accuracy: 55.6133 %, Loss: 1.4417\n",
      "epoch [9/80] need time 215.2004\n",
      "train epoch9\n",
      "Train Accuracy: 59.2422 %, Loss: 1.3119\n",
      "test epoch9\n",
      "Test Accuracy: 53.9733 %, Loss: 1.5704\n",
      "epoch [10/80] need time 215.0947\n",
      "train epoch10\n",
      "Train Accuracy: 60.4311 %, Loss: 1.2700\n",
      "test epoch10\n",
      "Test Accuracy: 57.3467 %, Loss: 1.3894\n",
      "epoch [11/80] need time 215.4033\n",
      "train epoch11\n",
      "Train Accuracy: 61.7244 %, Loss: 1.2255\n",
      "test epoch11\n",
      "Test Accuracy: 56.8867 %, Loss: 1.4391\n",
      "epoch [12/80] need time 215.7280\n",
      "train epoch12\n",
      "Train Accuracy: 62.7422 %, Loss: 1.1963\n",
      "test epoch12\n",
      "Test Accuracy: 54.1400 %, Loss: 1.5333\n",
      "epoch [13/80] need time 216.0028\n",
      "train epoch13\n",
      "Train Accuracy: 63.3222 %, Loss: 1.1683\n",
      "test epoch13\n",
      "Test Accuracy: 57.2667 %, Loss: 1.3697\n",
      "epoch [14/80] need time 216.3224\n",
      "train epoch14\n",
      "Train Accuracy: 64.1600 %, Loss: 1.1411\n",
      "test epoch14\n",
      "Test Accuracy: 60.0733 %, Loss: 1.2930\n",
      "epoch [15/80] need time 216.3193\n",
      "train epoch15\n",
      "Train Accuracy: 64.9622 %, Loss: 1.1135\n",
      "test epoch15\n",
      "Test Accuracy: 58.0200 %, Loss: 1.3843\n",
      "epoch [16/80] need time 216.4140\n",
      "train epoch16\n",
      "Train Accuracy: 65.1844 %, Loss: 1.1027\n",
      "test epoch16\n",
      "Test Accuracy: 62.6467 %, Loss: 1.2067\n",
      "epoch [17/80] need time 216.4506\n",
      "train epoch17\n",
      "Train Accuracy: 66.3222 %, Loss: 1.0693\n",
      "test epoch17\n",
      "Test Accuracy: 61.4733 %, Loss: 1.2385\n",
      "epoch [18/80] need time 216.5110\n",
      "train epoch18\n",
      "Train Accuracy: 66.9156 %, Loss: 1.0489\n",
      "test epoch18\n",
      "Test Accuracy: 63.0733 %, Loss: 1.2043\n",
      "epoch [19/80] need time 216.0918\n",
      "train epoch19\n",
      "Train Accuracy: 67.6689 %, Loss: 1.0294\n",
      "test epoch19\n",
      "Test Accuracy: 63.7467 %, Loss: 1.1762\n",
      "epoch [20/80] need time 215.2315\n",
      "train epoch20\n",
      "Train Accuracy: 68.1156 %, Loss: 1.0009\n",
      "test epoch20\n",
      "Test Accuracy: 64.5600 %, Loss: 1.1413\n",
      "epoch [21/80] need time 215.0568\n",
      "train epoch21\n",
      "Train Accuracy: 68.7444 %, Loss: 0.9878\n",
      "test epoch21\n",
      "Test Accuracy: 63.6200 %, Loss: 1.1853\n",
      "epoch [22/80] need time 216.0681\n",
      "train epoch22\n",
      "Train Accuracy: 69.1978 %, Loss: 0.9744\n",
      "test epoch22\n",
      "Test Accuracy: 63.1733 %, Loss: 1.1679\n",
      "epoch [23/80] need time 217.0924\n",
      "train epoch23\n",
      "Train Accuracy: 69.4511 %, Loss: 0.9664\n",
      "test epoch23\n",
      "Test Accuracy: 62.1600 %, Loss: 1.2259\n",
      "epoch [24/80] need time 217.1574\n",
      "train epoch24\n",
      "Train Accuracy: 69.8911 %, Loss: 0.9450\n",
      "test epoch24\n",
      "Test Accuracy: 65.2000 %, Loss: 1.1366\n",
      "epoch [25/80] need time 215.5429\n",
      "train epoch25\n",
      "Train Accuracy: 69.9422 %, Loss: 0.9398\n",
      "test epoch25\n",
      "Test Accuracy: 64.3267 %, Loss: 1.1766\n",
      "epoch [26/80] need time 214.9672\n",
      "train epoch26\n",
      "Train Accuracy: 71.0089 %, Loss: 0.9097\n",
      "test epoch26\n",
      "Test Accuracy: 64.3600 %, Loss: 1.1406\n",
      "epoch [27/80] need time 214.9385\n",
      "train epoch27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-440:\n",
      "Process Process-437:\n",
      "Process Process-433:\n",
      "Process Process-439:\n",
      "Process Process-438:\n",
      "Process Process-436:\n",
      "Process Process-434:\n",
      "Process Process-435:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "  File \"/usr/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "  File \"/usr/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "    self.run()\n",
      "  File \"/usr/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "  File \"/usr/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "  File \"/usr/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "  File \"/usr/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "    self.run()\n",
      "    self.run()\n",
      "    self.run()\n",
      "  File \"/usr/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "    self.run()\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    self.run()\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "  File \"/usr/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "  File \"/usr/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "  File \"/usr/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/torch/utils/data/dataloader.py\", line 106, in _worker_loop\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "  File \"/usr/lib/python2.7/multiprocessing/queues.py\", line 131, in get\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "  File \"/usr/lib/python2.7/multiprocessing/queues.py\", line 131, in get\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "  File \"/usr/lib/python2.7/multiprocessing/queues.py\", line 131, in get\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "    if timeout < 0 or not self._poll(timeout):\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/usr/lib/python2.7/multiprocessing/queues.py\", line 131, in get\n",
      "    if timeout < 0 or not self._poll(timeout):\n",
      "  File \"/usr/lib/python2.7/multiprocessing/queues.py\", line 131, in get\n",
      "  File \"/usr/lib/python2.7/multiprocessing/queues.py\", line 131, in get\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/torchvision/datasets/folder.py\", line 101, in __getitem__\n",
      "KeyboardInterrupt\n",
      "    if timeout < 0 or not self._poll(timeout):\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    if timeout < 0 or not self._poll(timeout):\n",
      "    if timeout < 0 or not self._poll(timeout):\n",
      "    if timeout < 0 or not self._poll(timeout):\n",
      "    sample = self.loader(path)\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/torchvision/datasets/folder.py\", line 147, in default_loader\n",
      "  File \"/usr/lib/python2.7/multiprocessing/queues.py\", line 131, in get\n",
      "    if timeout < 0 or not self._poll(timeout):\n",
      "KeyboardInterrupt\n",
      "    return pil_loader(path)\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/torchvision/datasets/folder.py\", line 130, in pil_loader\n",
      "    return img.convert('RGB')\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/PIL/Image.py\", line 875, in convert\n",
      "    self.load()\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/PIL/ImageFile.py\", line 236, in load\n",
      "    n, err_code = decoder.decode(b)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-c1c8f5014152>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mtotal\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/torch/nn/modules/module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-d1308b3994a9>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv13\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn13\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu13\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool13\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv14\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/torch/nn/modules/module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    470\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    471\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 472\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    473\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tracing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/collections.pyc\u001b[0m in \u001b[0;36mvalues\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    121\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0;34m'od.values() -> list of values in od'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/collections.pyc\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mcurr\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mroot\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mcurr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m                               \u001b[0;31m# yield the curr[KEY]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m             \u001b[0mcurr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcurr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m                              \u001b[0;31m# move to next node\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reversed__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#model.load_state_dict(torch.load('epoch39_weight.pkl'))\n",
    "num_epochs = 80\n",
    "for epoch in range(0,num_epochs):\n",
    "    batch_size_start = time.time()\n",
    "    running_loss = 0.0\n",
    "    corret,total = 0,0\n",
    "    print('train epoch%d'%epoch)\n",
    "    for i,(inputs, labels) in enumerate(train_loader):\n",
    "        inputs = inputs.cuda()\n",
    "        labels = labels.cuda()\n",
    "        inputs = Variable(inputs)\n",
    "        lables = Variable(labels)\n",
    "        lr=poly(0.01,4,num_epochs,epoch)\n",
    "        optimizer = torch.optim.SGD(model.parameters(), lr, momentum=0.9)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        _,predicted = torch.max(outputs.data,1)\n",
    "        total += labels.size(0)\n",
    "        corret += (predicted == labels).sum()\n",
    "        loss = loss_func(outputs, labels)        #交叉熵\n",
    "        loss.backward()\n",
    "        optimizer.step()                          #更新权重\n",
    "        running_loss += loss.data[0]\n",
    "    accuracy = 100 * float(corret) / float(total)\n",
    "    running_loss = running_loss / (45000 / batchsize)\n",
    "    print('Train Accuracy: %.4f %%, Loss: %.4f' % (accuracy, running_loss))\n",
    "    print('test epoch%d'%epoch)\n",
    "    test(model,val_loader)\n",
    "    torch.save(model.state_dict(),'epoch%d_weight.pkl'%epoch)\n",
    "    print('epoch [%d/%d] need time %.4f' % (epoch + 1, num_epochs, time.time() - batch_size_start))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = []\n",
    "loss = []\n",
    "for i in range(32):\n",
    "    print('prune fm %d' % i)\n",
    "    model.load_state_dict(torch.load('epoch54_weight.pkl'))\n",
    "    conv1_weight = model.conv1.weight.data.cpu().numpy()\n",
    "    zeros = np.zeros(conv1_weight[0].shape)\n",
    "    conv1_weight[i]=zeros\n",
    "    model.conv1.weight.data=torch.from_numpy(conv1_weight).cuda()\n",
    "    accuracy_tmp,loss_tmp = test(model,val_loader)\n",
    "    accuracy.append(accuracy_tmp)\n",
    "    loss.append(loss_tmp)\n",
    "for i in range(model.conv2.out_channels):\n",
    "    print('prune fm %d' % i)\n",
    "    model.load_state_dict(torch.load('epoch54_weight.pkl'))\n",
    "    conv_weight = model.conv2.weight.data.cpu().numpy()\n",
    "    zeros = np.zeros(conv_weight[0].shape)\n",
    "    conv_weight[i]=zeros\n",
    "    model.conv2.weight.data=torch.from_numpy(conv_weight).cuda()\n",
    "    accuracy_tmp,loss_tmp = test(model,val_loader)\n",
    "    accuracy.append(accuracy_tmp)\n",
    "    loss.append(loss_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prune_weight(in_remain,out_remain,layer,pruned_layer,layer_index,prune_model_config):\n",
    "    in_channel=0\n",
    "    out_channel=0\n",
    "    weight_remain=layer.weight.data.cpu().numpy()[:prune_model_config[layer_index],:prune_model_config[layer_index-1]]\n",
    "    for i in out_remain:\n",
    "        for j in in_remain:\n",
    "            weight_remain[out_channel,in_channel]=weight[i,j]\n",
    "            in_channel=in_channel+1\n",
    "        in_channel=0\n",
    "        out_channel=out_channel+1\n",
    "    pruned_layer.weight.data = torch.from_numpy(weight_remain).cuda()\n",
    "\n",
    "def prune_batchnorm(remain,layer,pruned_layer,layer_index,prune_model_config):\n",
    "    channel=0\n",
    "    weight_remain=np.zeros(prune_model_config[layer_index])\n",
    "    bias_remain=np.zeros(prune_model_config[layer_index])\n",
    "    mean_remain=np.zeros(prune_model_config[layer_index])\n",
    "    var_remain=np.zeros(prune_model_config[layer_index])\n",
    "    for i in remain:\n",
    "        weight_remain[channel]=layer.weight.data.cpu().numpy()[i]\n",
    "        bias_remain[channel]=layer.bias.data.cpu().numpy()[i]\n",
    "        mean_remain[channel]=layer.running_mean.data.cpu().numpy()[i]\n",
    "        var_remain[channel]=layer.running_var.data.cpu().numpy()[i]\n",
    "        channel = channel + 1\n",
    "    pruned_layer.weight.data = torch.from_numpy(weight_remain).cuda()\n",
    "    pruned_layer.bias.data = torch.from_numpy(bias_remain).cuda()\n",
    "    pruned_layer.running_mean.data = torch.from_numpy(mean_remain).cuda()\n",
    "    pruned_layer.running_var.data = torch.from_numpy(var_remain).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config = [32,64,128,64,128,256,128,256,512,256,512,256,512,1024,512,1024,512]\n",
    "prune_model_config = [16,32,64,32,64,128,64,128,256,128,256,128,256,512,256,512,256]\n",
    "layer_cnt = 58\n",
    "layer_index = 0\n",
    "\n",
    "for i in range(layer_cnt):\n",
    "    _,pruned_layer = pruned_model._modules.items()[i]\n",
    "    _,layer = model._modules.items()[i]\n",
    "    if (str(pruned_layer.type).find(\"Conv2d\") >= 0):\n",
    "        print 'conv%d'%(layer_index+1)\n",
    "        if(layer_index == 0):\n",
    "            out_remain=[]\n",
    "            \n",
    "            pruned_layer.out_channels = prune_model_config[layer_index]\n",
    "            #print 'out_channels = %d' % pruned_layer.out_channels\n",
    "            #weight = layer.weight.data.cpu().numpy()\n",
    "            prune_weight()\n",
    "            \n",
    "        elif(layer_index == 17):\n",
    "            pruned_layer.in_channels = prune_model_config[layer_index - 1]\n",
    "            #print 'in_channels = %d' % pruned_layer.in_channels\n",
    "            #weight = layer.weight.data.cpu().numpy()\n",
    "            pruned_weight = layer.weight.data.cpu().numpy()[:prune_model_config[layer_index - 1]]\n",
    "            pruned_layer.weight.data = torch.from_numpy(pruned_weight).cuda()\n",
    "            \n",
    "        else:\n",
    "            pruned_layer.in_channels = prune_model_config[layer_index - 1]\n",
    "            pruned_layer.out_channels = prune_model_config[layer_index]\n",
    "            #print 'in_channels = %d' % pruned_layer.in_channels\n",
    "            #print 'out_channels = %d' % pruned_layer.out_channels\n",
    "            #weight = layer.weight.data.cpu().numpy()\n",
    "            pruned_weight = layer.weight.data.cpu().numpy()[:prune_model_config[layer_index]]\n",
    "            pruned_layer.weight.data = torch.from_numpy(pruned_weight).cuda()\n",
    "            \n",
    "    elif (str(pruned_layer.type).find(\"BatchNorm2d\") >= 0):\n",
    "        print 'bn%d'%(layer_index+1)\n",
    "        pruned_layer.num_features = prune_model_config[layer_index]\n",
    "        print 'num_features = %d'% pruned_layer.num_features\n",
    "        pruned_layer.weight\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        layer_index = layer_index + 1\n",
    "    elif (str(pruned_layer.type).find(\"MaxPool2d\") >= 0):\n",
    "        print 'MaxPool2d'\n",
    "    elif (str(pruned_layer.type).find(\"AvgPool2d\") >= 0):\n",
    "        print 'AvgPool2d'\n",
    "    else:\n",
    "        print 'LeakyReLU'\n",
    "print pruned_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# loss_rank:删掉每个feature map后的loss排名\n",
    "# model_config:原模型中每个卷积层的层数\n",
    "# prune_cnt:要被删除的feature map层数\n",
    "# remain_config:每一个卷积层要保留的feature map的编号\n",
    "def generate_remain_config(loss_rank,model_config,prune_cnt):\n",
    "    #准备一个二维数组\n",
    "    remain_config=[[]]\n",
    "    for i in range(len(model_config)-1):\n",
    "        remain_config.append([])\n",
    "    \n",
    "    fm_cnt=len(loss_rank) - prune_cnt#要保留的feature map个数\n",
    "    layer_index=0\n",
    "    fm_index=0\n",
    "    for i in range(fm_cnt):\n",
    "        layer_index,fm_index=get_layer_fm_index(loss_rank[i])\n",
    "        remain_config[layer_index].append(fm_index)\n",
    "    \n",
    "    return remain_config\n",
    "\n",
    "def generate_prune_model_config(remain_config):\n",
    "    layer_cnt=len(remain_config)\n",
    "    prune_model_config=[]\n",
    "    for i in range(layer_cnt):\n",
    "        prune_model_config.append(len(remain_config[i]))\n",
    "    return prune_model_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21, 32, 71, 33, 62, 130, 61, 127, 239, 108, 254, 127, 247, 507, 270, 537, 262]\n"
     ]
    }
   ],
   "source": [
    "loss = np.random.random(6176)\n",
    "loss_rank = np.argsort(loss)\n",
    "remain_config=generate_remain_config(loss_rank,model_config,3088)\n",
    "prune_model_config=generate_prune_model_config(remain_config)\n",
    "print prune_model_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 18, 3, 3)\n"
     ]
    }
   ],
   "source": [
    "conv1_remain=[0,1,2,4,6,7,8,9,12,15,17,19,20,21,23,24]\n",
    "conv2_remain=[0,1,2,4,6,7,8,9,12,15,17,19,20,21,23,24,25,26,27,28,29,33,34,35,36,37,39,41,43,44,45,47]\n",
    "prune_model_config=[18,32,64,32,64,128,64,128,256,128,256,128,256,512,256,512,256]\n",
    "conv2_weight = model.conv2.weight.data.cpu().numpy()\n",
    "conv2_weight_remain=prune_weight(conv1_remain,conv2_remain,model.conv2.weight.data.cpu().numpy(),prune_model_config,1)\n",
    "print conv2_weight_remain.shape\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
